{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoRes Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/fuyu-quant/autores-evaluator/blob/main/examples/cnn.ipynb\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install autoresevaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/fuyu-quant/A_B-dataset.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\"\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"YOUR_API_KEY\"\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = \"YOUR_API_KEY\"\n",
    "\n",
    "\n",
    "from autoresevaluator import AutoResEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## サンプルのモデルを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# いくつか追加したロジスティック回帰\n",
    "sample_model = \"\"\"\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def train(trainloader, params):\n",
    "    net = Net()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=params['lr'], momentum=0.9)\n",
    "\n",
    "    for epoch in range(1):  # データセットを複数回繰り返して学習\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # 入力データを取得\n",
    "            inputs, labels = data\n",
    "\n",
    "            # 勾配をゼロにする\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 順伝播 + 逆伝播 + 最適化\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # 統計を表示\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # 2000ミニバッチごとに表示\n",
    "                #print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "                running_loss = 0.0\n",
    "    return net\n",
    "\n",
    "def test(net, testloader):\n",
    "    all_outputs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            probabilities = F.softmax(outputs, dim=1)\n",
    "            probabilities_np = probabilities.numpy().tolist()\n",
    "            all_outputs.extend(probabilities_np)\n",
    "\n",
    "    all_outputs_np = np.array(all_outputs)\n",
    "    return all_outputs_np\n",
    "\n",
    "def model(trainloader, testloader, params):\n",
    "    net = train(trainloader, params)\n",
    "    y_pred = test(net, testloader)\n",
    "    return y_pred\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "with open('/content/example.py', 'w') as file:\n",
    "    file.write(sample_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoResEvaluatorの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'lr': {'type': 'log_float', 'args': [1e-5, 1e-3]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "are = AutoResEvaluator(\n",
    "    dataset_name='cifar10',\n",
    "    model_path='/content/example.py',\n",
    "    params=params,\n",
    "    valuation_index='accuracy',\n",
    "    datasave_path='./data'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoResEvaluatorの実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "are.exec()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
